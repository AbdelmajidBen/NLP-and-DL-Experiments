{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa0299b9-c274-4cde-b558-921cd565cd59",
   "metadata": {},
   "source": [
    "## NLP LAB 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b8c670-8f71-4fbf-8b2e-ce6797a153b9",
   "metadata": {},
   "source": [
    "### Objective : The main purpose behind this lab is to get familiar with NLP language models using Sklearn library.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe0d0f6-5429-4a8a-bec6-d88c84240973",
   "metadata": {},
   "source": [
    "#### Part 2 Language Modeling / Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b8c6ad-7a89-4fd0-ae26-80fc09c66127",
   "metadata": {},
   "source": [
    "Importing the necessary librarys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d25d812-27e9-469f-8185-487323711878",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "from gensim.models import Word2Vec\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6b6f2d-6515-4267-ba9e-5b171539e89f",
   "metadata": {},
   "source": [
    "Downloading the necessary nltk data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3447948e-d3d7-4556-8704-063dcebfbf56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/mac/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/mac/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1021f00-9fc3-4b0f-a641-18b672cc22c9",
   "metadata": {},
   "source": [
    "As the data don't have a column name we have given them a one "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94a876a6-af39-4497-89a8-838904f29905",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('twitter_training.csv', header=None, names=['ID', 'Platform', 'Sentiment', 'Text'])  # Update with your train dataset path\n",
    "valid_df = pd.read_csv('twitter_validation.csv', header=None, names=['ID', 'Platform', 'Sentiment', 'Text'])  # Update with your validation dataset path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2842434-982b-4339-894a-f14b67333428",
   "metadata": {},
   "source": [
    "Droping the NAN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0aec87ba-b5b5-402f-9e10-b74a366d70f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.dropna(inplace=True)\n",
    "valid_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41b1d52-9572-4856-9a83-6f8eec2114e0",
   "metadata": {},
   "source": [
    "Defining the process Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22a8746d-c6bf-4f76-b456-c49ba96a83fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    # Remove special characters and digits\n",
    "    text = re.sub(r'\\W', ' ', text)\n",
    "    text = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', text)\n",
    "    text = re.sub(r'\\^[a-zA-Z]\\s+', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text, flags=re.I)\n",
    "    text = re.sub(r'^b\\s+', '', text)\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Tokenization\n",
    "    text = text.split()\n",
    "    \n",
    "    # Lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    text = [lemmatizer.lemmatize(word) for word in text if word not in set(stopwords.words('english'))]\n",
    "    text = ' '.join(text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a14dd8d9-b644-4a31-9191-81a83433262d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['cleaned_text'] = train_df['Text'].apply(preprocess)\n",
    "valid_df['cleaned_text'] = valid_df['Text'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a4757e-5196-4f0c-ac5e-9da256fd14cb",
   "metadata": {},
   "source": [
    "Splliting the data into test and training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e65909e-f2d4-4a54-83cb-223534b59d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full = train_df['cleaned_text']\n",
    "y_train_full = train_df['Sentiment']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train_full, y_train_full, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179db000-cab5-4f5b-9fa5-e38a5efbd2a8",
   "metadata": {},
   "source": [
    "Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ddbd1b0-f624-445f-b45a-f31c272046cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid = valid_df['cleaned_text']\n",
    "y_valid = valid_df['Sentiment']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9082c66d-8e0b-420c-8454-a5b251c70394",
   "metadata": {},
   "source": [
    "Feature Extraction using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d73f076-6f33-47ed-b3e8-8ec4d6125194",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_valid_tfidf = tfidf_vectorizer.transform(X_valid)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2381f3c9-4b3b-44d4-ab8b-ecf24320cc3b",
   "metadata": {},
   "source": [
    "Feature Extraction Using BOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0dfcbce1-db85-472f-a7fb-607eb80aafe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(max_features=5000)\n",
    "X_train_bow = count_vectorizer.fit_transform(X_train)\n",
    "X_valid_bow = count_vectorizer.transform(X_valid)\n",
    "X_test_bow = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55bb84b-18fa-4fb4-9aab-4d796edd4848",
   "metadata": {},
   "source": [
    "Feature Extraction Using W2V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3fff93f-299a-48e9-b612-52c0ecd94efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_word2vec = [text.split() for text in X_train]\n",
    "X_valid_word2vec = [text.split() for text in X_valid]\n",
    "X_test_word2vec = [text.split() for text in X_test]\n",
    "word2vec_model = Word2Vec(X_train_word2vec, vector_size=100, window=5, min_count=2, workers=4)\n",
    "X_train_word2vec = np.array([np.mean([word2vec_model.wv[word] for word in words if word in word2vec_model.wv] or [np.zeros(100)], axis=0) for words in X_train_word2vec])\n",
    "X_valid_word2vec = np.array([np.mean([word2vec_model.wv[word] for word in words if word in word2vec_model.wv] or [np.zeros(100)], axis=0) for words in X_valid_word2vec])\n",
    "X_test_word2vec = np.array([np.mean([word2vec_model.wv[word] for word in words if word in word2vec_model.wv] or [np.zeros(100)], axis=0) for words in X_test_word2vec])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60634ba-01d1-4840-a5d6-d223582f562d",
   "metadata": {},
   "source": [
    "Model Training & Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a893c22-2eaf-4e07-9e45-875667a3feb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_model(model, X_train, X_valid, X_test, y_train, y_valid, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred_valid = model.predict(X_valid)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    \n",
    "    accuracy_valid = accuracy_score(y_valid, y_pred_valid)\n",
    "    f1_valid = f1_score(y_valid, y_pred_valid, average='weighted')\n",
    "    \n",
    "    accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "    f1_test = f1_score(y_test, y_pred_test, average='weighted')\n",
    "    \n",
    "    print(f'Validation Accuracy: {accuracy_valid}')\n",
    "    print(f'Validation F1 Score: {f1_valid}')\n",
    "    print(confusion_matrix(y_valid, y_pred_valid))\n",
    "    print(classification_report(y_valid, y_pred_valid))\n",
    "    \n",
    "    print(f'Test Accuracy: {accuracy_test}')\n",
    "    print(f'Test F1 Score: {f1_test}')\n",
    "    print(confusion_matrix(y_test, y_pred_test))\n",
    "    print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82e4f8bc-6e16-498d-8346-2b010a6aa4fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes with TF-IDF:\n",
      "Validation Accuracy: 0.707\n",
      "Validation F1 Score: 0.7020818765440422\n",
      "[[ 88  34  12  38]\n",
      " [  1 221  20  24]\n",
      " [ 12  57 173  43]\n",
      " [  3  29  20 225]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Irrelevant       0.85      0.51      0.64       172\n",
      "    Negative       0.65      0.83      0.73       266\n",
      "     Neutral       0.77      0.61      0.68       285\n",
      "    Positive       0.68      0.81      0.74       277\n",
      "\n",
      "    accuracy                           0.71      1000\n",
      "   macro avg       0.74      0.69      0.70      1000\n",
      "weighted avg       0.73      0.71      0.70      1000\n",
      "\n",
      "Test Accuracy: 0.6331081081081081\n",
      "Test F1 Score: 0.6191323675481166\n",
      "[[ 886  735  316  759]\n",
      " [  71 3519  308  482]\n",
      " [ 145  797 1916  747]\n",
      " [  89  641  340 3049]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Irrelevant       0.74      0.33      0.46      2696\n",
      "    Negative       0.62      0.80      0.70      4380\n",
      "     Neutral       0.67      0.53      0.59      3605\n",
      "    Positive       0.61      0.74      0.67      4119\n",
      "\n",
      "    accuracy                           0.63     14800\n",
      "   macro avg       0.66      0.60      0.60     14800\n",
      "weighted avg       0.65      0.63      0.62     14800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Naive Bayes with TF-IDF:\")\n",
    "train_and_evaluate_model(MultinomialNB(), X_train_tfidf, X_valid_tfidf, X_test_tfidf, y_train, y_valid, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b6f1bbc-faed-4187-bad8-7afe9f900137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression with TF-IDF:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.81\n",
      "Validation F1 Score: 0.8091765188148115\n",
      "[[121  19  10  22]\n",
      " [  4 235  14  13]\n",
      " [ 12  35 223  15]\n",
      " [ 11  19  16 231]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Irrelevant       0.82      0.70      0.76       172\n",
      "    Negative       0.76      0.88      0.82       266\n",
      "     Neutral       0.85      0.78      0.81       285\n",
      "    Positive       0.82      0.83      0.83       277\n",
      "\n",
      "    accuracy                           0.81      1000\n",
      "   macro avg       0.81      0.80      0.80      1000\n",
      "weighted avg       0.81      0.81      0.81      1000\n",
      "\n",
      "Test Accuracy: 0.6831081081081081\n",
      "Test F1 Score: 0.6785814782219962\n",
      "[[1353  522  349  472]\n",
      " [ 160 3519  326  375]\n",
      " [ 212  608 2240  545]\n",
      " [ 210  526  385 2998]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Irrelevant       0.70      0.50      0.58      2696\n",
      "    Negative       0.68      0.80      0.74      4380\n",
      "     Neutral       0.68      0.62      0.65      3605\n",
      "    Positive       0.68      0.73      0.70      4119\n",
      "\n",
      "    accuracy                           0.68     14800\n",
      "   macro avg       0.69      0.66      0.67     14800\n",
      "weighted avg       0.68      0.68      0.68     14800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression with TF-IDF:\")\n",
    "train_and_evaluate_model(LogisticRegression(), X_train_tfidf, X_valid_tfidf, X_test_tfidf, y_train, y_valid, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6698102b-49e8-4faa-b743-12f0e78c1df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost with TF-IDF:\n",
      "Validation Accuracy: 0.483\n",
      "Validation F1 Score: 0.450813740497023\n",
      "[[ 12  92  32  36]\n",
      " [  6 211  31  18]\n",
      " [  3 113 123  46]\n",
      " [  4 104  32 137]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Irrelevant       0.48      0.07      0.12       172\n",
      "    Negative       0.41      0.79      0.54       266\n",
      "     Neutral       0.56      0.43      0.49       285\n",
      "    Positive       0.58      0.49      0.53       277\n",
      "\n",
      "    accuracy                           0.48      1000\n",
      "   macro avg       0.51      0.45      0.42      1000\n",
      "weighted avg       0.51      0.48      0.45      1000\n",
      "\n",
      "Test Accuracy: 0.4685135135135135\n",
      "Test F1 Score: 0.4314811494333045\n",
      "[[ 234 1593  293  576]\n",
      " [  88 3605  365  322]\n",
      " [  48 1740 1269  548]\n",
      " [  53 1886  354 1826]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Irrelevant       0.55      0.09      0.15      2696\n",
      "    Negative       0.41      0.82      0.55      4380\n",
      "     Neutral       0.56      0.35      0.43      3605\n",
      "    Positive       0.56      0.44      0.49      4119\n",
      "\n",
      "    accuracy                           0.47     14800\n",
      "   macro avg       0.52      0.43      0.41     14800\n",
      "weighted avg       0.51      0.47      0.43     14800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"AdaBoost with TF-IDF:\")\n",
    "train_and_evaluate_model(AdaBoostClassifier(), X_train_tfidf, X_valid_tfidf, X_test_tfidf, y_train, y_valid, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "118a56ca-2299-491e-b865-0717783123b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes with Bag of Words:\n",
      "Validation Accuracy: 0.705\n",
      "Validation F1 Score: 0.7021519169685826\n",
      "[[104  27  12  29]\n",
      " [ 11 207  24  24]\n",
      " [ 21  45 172  47]\n",
      " [  6  27  22 222]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Irrelevant       0.73      0.60      0.66       172\n",
      "    Negative       0.68      0.78      0.72       266\n",
      "     Neutral       0.75      0.60      0.67       285\n",
      "    Positive       0.69      0.80      0.74       277\n",
      "\n",
      "    accuracy                           0.70      1000\n",
      "   macro avg       0.71      0.70      0.70      1000\n",
      "weighted avg       0.71      0.70      0.70      1000\n",
      "\n",
      "Test Accuracy: 0.6288513513513514\n",
      "Test F1 Score: 0.6223075619154208\n",
      "[[1199  550  304  643]\n",
      " [ 214 3287  374  505]\n",
      " [ 318  691 1860  736]\n",
      " [ 223  567  368 2961]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Irrelevant       0.61      0.44      0.52      2696\n",
      "    Negative       0.65      0.75      0.69      4380\n",
      "     Neutral       0.64      0.52      0.57      3605\n",
      "    Positive       0.61      0.72      0.66      4119\n",
      "\n",
      "    accuracy                           0.63     14800\n",
      "   macro avg       0.63      0.61      0.61     14800\n",
      "weighted avg       0.63      0.63      0.62     14800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Naive Bayes with Bag of Words:\")\n",
    "train_and_evaluate_model(MultinomialNB(), X_train_bow, X_valid_bow, X_test_bow, y_train, y_valid, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ecf932b9-8521-448b-a406-18bdc9b68c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression with Bag of Words:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.838\n",
      "Validation F1 Score: 0.8377441738960172\n",
      "[[132  11   6  23]\n",
      " [  5 237   9  15]\n",
      " [ 11  22 233  19]\n",
      " [ 12  14  15 236]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Irrelevant       0.82      0.77      0.80       172\n",
      "    Negative       0.83      0.89      0.86       266\n",
      "     Neutral       0.89      0.82      0.85       285\n",
      "    Positive       0.81      0.85      0.83       277\n",
      "\n",
      "    accuracy                           0.84      1000\n",
      "   macro avg       0.84      0.83      0.83      1000\n",
      "weighted avg       0.84      0.84      0.84      1000\n",
      "\n",
      "Test Accuracy: 0.7066891891891892\n",
      "Test F1 Score: 0.7040570919399934\n",
      "[[1504  360  300  532]\n",
      " [ 152 3446  296  486]\n",
      " [ 226  416 2289  674]\n",
      " [ 219  339  341 3220]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Irrelevant       0.72      0.56      0.63      2696\n",
      "    Negative       0.76      0.79      0.77      4380\n",
      "     Neutral       0.71      0.63      0.67      3605\n",
      "    Positive       0.66      0.78      0.71      4119\n",
      "\n",
      "    accuracy                           0.71     14800\n",
      "   macro avg       0.71      0.69      0.70     14800\n",
      "weighted avg       0.71      0.71      0.70     14800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression with Bag of Words:\")\n",
    "train_and_evaluate_model(LogisticRegression(), X_train_bow, X_valid_bow, X_test_bow, y_train, y_valid, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bdd36d-e813-4f18-89cb-7e4603b95790",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e83317c6-de96-4c4e-89d3-e70214e599db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost with Bag of Words:\n",
      "Validation Accuracy: 0.483\n",
      "Validation F1 Score: 0.44756014772991\n",
      "[[ 11  85  34  42]\n",
      " [  4 210  27  25]\n",
      " [  4 101 121  59]\n",
      " [  2 101  33 141]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Irrelevant       0.52      0.06      0.11       172\n",
      "    Negative       0.42      0.79      0.55       266\n",
      "     Neutral       0.56      0.42      0.48       285\n",
      "    Positive       0.53      0.51      0.52       277\n",
      "\n",
      "    accuracy                           0.48      1000\n",
      "   macro avg       0.51      0.45      0.42      1000\n",
      "weighted avg       0.51      0.48      0.45      1000\n",
      "\n",
      "Test Accuracy: 0.47047297297297297\n",
      "Test F1 Score: 0.4320028484998988\n",
      "[[ 218 1542  310  626]\n",
      " [  79 3569  313  419]\n",
      " [  64 1655 1242  644]\n",
      " [  41 1814  330 1934]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Irrelevant       0.54      0.08      0.14      2696\n",
      "    Negative       0.42      0.81      0.55      4380\n",
      "     Neutral       0.57      0.34      0.43      3605\n",
      "    Positive       0.53      0.47      0.50      4119\n",
      "\n",
      "    accuracy                           0.47     14800\n",
      "   macro avg       0.51      0.43      0.40     14800\n",
      "weighted avg       0.51      0.47      0.43     14800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"AdaBoost with Bag of Words:\")\n",
    "train_and_evaluate_model(AdaBoostClassifier(), X_train_bow, X_valid_bow, X_test_bow, y_train, y_valid, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b71a02d5-3e86-480e-ad57-c27f8eca40ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression with Word2Vec:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.55\n",
      "Validation F1 Score: 0.5323963836775917\n",
      "[[ 33  51  36  52]\n",
      " [ 11 187  36  32]\n",
      " [ 13  68 151  53]\n",
      " [ 11  50  37 179]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Irrelevant       0.49      0.19      0.28       172\n",
      "    Negative       0.53      0.70      0.60       266\n",
      "     Neutral       0.58      0.53      0.55       285\n",
      "    Positive       0.57      0.65      0.60       277\n",
      "\n",
      "    accuracy                           0.55      1000\n",
      "   macro avg       0.54      0.52      0.51      1000\n",
      "weighted avg       0.55      0.55      0.53      1000\n",
      "\n",
      "Test Accuracy: 0.519054054054054\n",
      "Test F1 Score: 0.5043926950982146\n",
      "[[ 540  790  543  823]\n",
      " [ 303 3003  475  599]\n",
      " [ 320  791 1717  777]\n",
      " [ 326  755  616 2422]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Irrelevant       0.36      0.20      0.26      2696\n",
      "    Negative       0.56      0.69      0.62      4380\n",
      "     Neutral       0.51      0.48      0.49      3605\n",
      "    Positive       0.52      0.59      0.55      4119\n",
      "\n",
      "    accuracy                           0.52     14800\n",
      "   macro avg       0.49      0.49      0.48     14800\n",
      "weighted avg       0.50      0.52      0.50     14800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression with Word2Vec:\")\n",
    "train_and_evaluate_model(LogisticRegression(), X_train_word2vec, X_valid_word2vec, X_test_word2vec, y_train, y_valid, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9bc2da-ef63-4b46-aeda-55fe3182bb8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4313ade3-c4f4-44c6-a7e9-29e18f354ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost with Word2Vec:\n",
      "Validation Accuracy: 0.509\n",
      "Validation F1 Score: 0.4986764981442086\n",
      "[[ 42  50  36  44]\n",
      " [ 18 178  34  36]\n",
      " [ 21  68 141  55]\n",
      " [ 14  62  53 148]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Irrelevant       0.44      0.24      0.31       172\n",
      "    Negative       0.50      0.67      0.57       266\n",
      "     Neutral       0.53      0.49      0.51       285\n",
      "    Positive       0.52      0.53      0.53       277\n",
      "\n",
      "    accuracy                           0.51      1000\n",
      "   macro avg       0.50      0.49      0.48      1000\n",
      "weighted avg       0.51      0.51      0.50      1000\n",
      "\n",
      "Test Accuracy: 0.4983108108108108\n",
      "Test F1 Score: 0.4850975271239729\n",
      "[[ 581  808  478  829]\n",
      " [ 255 2824  523  778]\n",
      " [ 286  792 1579  948]\n",
      " [ 285  805  638 2391]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Irrelevant       0.41      0.22      0.28      2696\n",
      "    Negative       0.54      0.64      0.59      4380\n",
      "     Neutral       0.49      0.44      0.46      3605\n",
      "    Positive       0.48      0.58      0.53      4119\n",
      "\n",
      "    accuracy                           0.50     14800\n",
      "   macro avg       0.48      0.47      0.47     14800\n",
      "weighted avg       0.49      0.50      0.49     14800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"AdaBoost with Word2Vec:\")\n",
    "train_and_evaluate_model(AdaBoostClassifier(), X_train_word2vec, X_valid_word2vec, X_test_word2vec, y_train, y_valid, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8216f0d1-9173-4b58-b2b7-0ec5b80b1097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM with TF-IDF:\n",
      "Validation Accuracy: 0.966\n",
      "Validation F1 Score: 0.9660746179549231\n",
      "[[165   2   1   4]\n",
      " [  0 260   1   5]\n",
      " [  1   2 273   9]\n",
      " [  4   1   4 268]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Irrelevant       0.97      0.96      0.96       172\n",
      "    Negative       0.98      0.98      0.98       266\n",
      "     Neutral       0.98      0.96      0.97       285\n",
      "    Positive       0.94      0.97      0.95       277\n",
      "\n",
      "    accuracy                           0.97      1000\n",
      "   macro avg       0.97      0.97      0.97      1000\n",
      "weighted avg       0.97      0.97      0.97      1000\n",
      "\n",
      "Test Accuracy: 0.895472972972973\n",
      "Test F1 Score: 0.8953878241992632\n",
      "[[2204  133  112  247]\n",
      " [  49 4039   75  217]\n",
      " [  46  120 3145  294]\n",
      " [  51   93  110 3865]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Irrelevant       0.94      0.82      0.87      2696\n",
      "    Negative       0.92      0.92      0.92      4380\n",
      "     Neutral       0.91      0.87      0.89      3605\n",
      "    Positive       0.84      0.94      0.88      4119\n",
      "\n",
      "    accuracy                           0.90     14800\n",
      "   macro avg       0.90      0.89      0.89     14800\n",
      "weighted avg       0.90      0.90      0.90     14800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"SVM with TF-IDF:\")\n",
    "train_and_evaluate_model(SVC(), X_train_tfidf, X_valid_tfidf, X_test_tfidf, y_train, y_valid, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86297802-b540-4e98-a190-f01d30e8ffb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM with Bag of Words:\n"
     ]
    }
   ],
   "source": [
    "print(\"SVM with Bag of Words:\")\n",
    "train_and_evaluate_model(SVC(), X_train_bow, X_valid_bow, X_test_bow, y_train, y_valid, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab426ed-15d8-4027-8ebf-bd51f30a5d64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
